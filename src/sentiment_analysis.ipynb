{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7409c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aj281\\OneDrive\\Desktop\\crypto sentiment analysis\\crypto_sentiment_trading\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df45b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c938eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 13)\n",
      "                                  user_name    user_location  \\\n",
      "0                             DeSota Wilson      Atlanta, GA   \n",
      "1                                  CryptoND              NaN   \n",
      "2                                 Tdlmatias  London, England   \n",
      "3                      Crypto is the future              NaN   \n",
      "4  Alex Kirchmaier ðŸ‡¦ðŸ‡¹ðŸ‡¸ðŸ‡ª #FactsSuperspreader           Europa   \n",
      "\n",
      "                                    user_description         user_created  \\\n",
      "0  Biz Consultant, real estate, fintech, startups...  2009-04-26 20:05:09   \n",
      "1  ðŸ˜Ž BITCOINLIVE is a Dutch platform aimed at inf...  2019-10-17 20:12:10   \n",
      "2  IM Academy : The best #forex, #SelfEducation, ...  2014-11-10 10:50:37   \n",
      "3  I will post a lot of buying signals for BTC tr...  2019-09-28 16:48:12   \n",
      "4  Co-founder @RENJERJerky | Forbes 30Under30 | I...  2016-02-03 13:15:55   \n",
      "\n",
      "   user_followers  user_friends  user_favourites  user_verified  \\\n",
      "0          8534.0          7605             4838          False   \n",
      "1          6769.0          1532            25483          False   \n",
      "2           128.0           332              924          False   \n",
      "3           625.0           129               14          False   \n",
      "4          1249.0          1472            10482          False   \n",
      "\n",
      "                  date                                               text  \\\n",
      "0  2021-02-10 23:59:04  Blue Ridge Bank shares halted by NYSE after #b...   \n",
      "1  2021-02-10 23:58:48  ðŸ˜Ž Today, that's this #Thursday, we will do a \"...   \n",
      "2  2021-02-10 23:54:48  Guys evening, I have read this article about B...   \n",
      "3  2021-02-10 23:54:33  $BTC A big chance in a billion! Price: \\487264...   \n",
      "4  2021-02-10 23:54:06  This network is secured by 9 508 nodes as of t...   \n",
      "\n",
      "                                    hashtags               source  is_retweet  \n",
      "0                                ['bitcoin']      Twitter Web App       False  \n",
      "1  ['Thursday', 'Btc', 'wallet', 'security']  Twitter for Android       False  \n",
      "2                                        NaN      Twitter Web App       False  \n",
      "3         ['Bitcoin', 'FX', 'BTC', 'crypto']              dlvr.it       False  \n",
      "4                                    ['BTC']      Twitter Web App       False  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/chunked_data/tweets_part_1.csv\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9940a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset\n",
      "Index(['user_name', 'user_location', 'user_description', 'user_created',\n",
      "       'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
      "       'date', 'text', 'hashtags', 'source', 'is_retweet'],\n",
      "      dtype='object')\n",
      "Columns after dropping some columns\n",
      "Index(['date', 'text', 'hashtags', 'is_retweet'], dtype='object')\n",
      "New shape of the dataset  (50000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in the dataset\")\n",
    "print(df.columns)\n",
    "columns_to_drop = [\n",
    "    'user_name', 'user_location', 'user_description', 'user_created',\n",
    "    'user_followers', 'user_friends', 'user_favourites', 'user_verified',\n",
    "    'source'\n",
    "] \n",
    "#remove the columns which are not needed for the analysis\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "print(\"Columns after dropping some columns\")\n",
    "print(df.columns)\n",
    "print(\"New shape of the dataset \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3ae857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 4)\n"
     ]
    }
   ],
   "source": [
    "df = df[df['is_retweet'] == False].reset_index(drop=True)\n",
    "print(df.shape)\n",
    "\n",
    "# Deleting the duplicate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5421a35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date              0\n",
      "text              0\n",
      "hashtags      10571\n",
      "is_retweet        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72a20c",
   "metadata": {},
   "source": [
    "## Cleaning the data for VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009b7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_for_vader(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    # Remove @mentions\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    # Remove hashtags \n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a98ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Blue Ridge Bank shares halted by NYSE after bi...\n",
      "1    ðŸ˜Ž Today, that's this Thursday, we will do a \"ðŸŽ¬...\n",
      "2    Guys evening, I have read this article about B...\n",
      "3    $BTC A big chance in a billion! Price: \\487264...\n",
      "4    This network is secured by 9 508 nodes as of t...\n",
      "5    ðŸ’¹ Trade Crypto on Binance ðŸ“Œ Enjoy Cashback 10%...\n",
      "6        &lt;'fire' &amp; 'man'&gt; Bitcoin Crypto BTC\n",
      "7    ðŸ”„ Prices update in $EUR (1 hour): $BTC - 37082...\n",
      "8    BTC Bitcoin Ethereum ETH Crypto cryptotrading ...\n",
      "9    .â€™s bitcoin investment is revolutionary for cr...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess_for_vader)\n",
    "\n",
    "print(df['text'].iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b8aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique languages detected in the dataset:\n",
      "['en' 'tl' 'pt' 'it' 'es' 'fr' 'hu' 'nl' 'de' 'vi' 'ca' 'no' 'so' 'sv'\n",
      " 'ro' 'th' 'fi' 'sl' 'af' 'tr' 'unknown' 'cy' 'id' 'da' 'sw' 'pl' 'hr'\n",
      " 'sk' 'ja' 'sq' 'ru']\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Ensure reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "\n",
    "# Apply language detection\n",
    "df['lang'] = df['text'].astype(str).apply(detect_language)\n",
    "\n",
    "# Show all unique languages detected\n",
    "unique_languages = df['lang'].unique()\n",
    "\n",
    "print(\"Unique languages detected in the dataset:\")\n",
    "print(unique_languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f570e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language frequencies in the dataset:\n",
      "lang\n",
      "en         49246\n",
      "de           149\n",
      "it            76\n",
      "nl            73\n",
      "unknown       66\n",
      "tl            56\n",
      "fr            55\n",
      "ca            35\n",
      "vi            34\n",
      "ro            25\n",
      "pt            22\n",
      "so            21\n",
      "cy            20\n",
      "hu            17\n",
      "da            15\n",
      "no            12\n",
      "es            11\n",
      "sv            11\n",
      "af            11\n",
      "tr            11\n",
      "fi             8\n",
      "id             8\n",
      "sl             5\n",
      "th             2\n",
      "sw             2\n",
      "pl             2\n",
      "hr             2\n",
      "sq             2\n",
      "sk             1\n",
      "ja             1\n",
      "ru             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def count_language_frequencies(df, lang_column='lang'):\n",
    "    return df[lang_column].value_counts()\n",
    "\n",
    "# Assuming df['lang'] has language codes\n",
    "lang_counts = count_language_frequencies(df)\n",
    "\n",
    "print(\"Language frequencies in the dataset:\")\n",
    "print(lang_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbed990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English tweets: 49246\n"
     ]
    }
   ],
   "source": [
    "def keep_only_english_tweets(df, lang_column='lang'):\n",
    "    return df[df[lang_column] == 'en'].copy()\n",
    "\n",
    "# Filtered DataFrame with only English tweets\n",
    "english_df = keep_only_english_tweets(df)\n",
    "\n",
    "# check how many remain\n",
    "print(f\"Number of English tweets: {len(english_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4ce88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df.to_csv('filtered_tweets_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b302f",
   "metadata": {},
   "source": [
    "## Assigning Labels to tweets Using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e40c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aj281\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia=SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_label(text):\n",
    "    # Get the sentiment scores\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    \n",
    "    # Determine the sentiment label based on the compound score\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f2fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment counts:\n",
      "sentiment\n",
      "neutral     21604\n",
      "positive    21374\n",
      "negative     7022\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df['text'].apply(get_sentiment_label)\n",
    "# Count the number of tweets in each sentiment category \n",
    "sentiment_counts = df['sentiment'].value_counts()  \n",
    "print(\"Sentiment counts:\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Save the DataFrame with sentiment labels to a CSV file\n",
    "df.to_csv('tweets_with_sentiment_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
