{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df45b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b97ef7",
   "metadata": {},
   "source": [
    "## Using DuckDB to handle large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c576e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x266d8206df0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read all CSVs (Feb 2021 to Sept 2021)\n",
    "query = \"\"\"\n",
    "    SELECT * FROM read_csv_auto('../dataset/monthly_tweets/tweets_*.csv', \n",
    "        columns={'date': 'VARCHAR', 'text': 'VARCHAR', 'is_retweet': 'BOOLEAN'})\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and get a DuckDB relation (can also `.to_df()` for pandas)\n",
    "tweets_rel = duckdb.query(query)\n",
    "\n",
    "# Optional: Create or connect to a DuckDB DB file\n",
    "conn = duckdb.connect('bitcoin_tweets.duckdb')\n",
    "\n",
    "# Create a persistent table (one-time operation)\n",
    "conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bitcoin_tweets AS\n",
    "    SELECT * FROM read_csv_auto('../dataset/monthly_tweets/tweets_*.csv', \n",
    "        columns={'date': 'VARCHAR', 'text': 'VARCHAR', 'is_retweet': 'BOOLEAN'})\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = conn.execute(\"\"\"\n",
    "    SELECT * FROM bitcoin_tweets\n",
    "    WHERE is_retweet = FALSE\n",
    "    AND date BETWEEN '2021-02-01' AND '2021-07-31'\n",
    "\"\"\").df()\n",
    "# Saving the data into a dataframe but tweets are from feb to july only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9377a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720268, 3)\n",
      "date          0\n",
      "text          0\n",
      "is_retweet    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72a20c",
   "metadata": {},
   "source": [
    "## Cleaning the data for VADER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009b7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_for_vader(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    # Remove @mentions\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    # Remove hashtags \n",
    "    text = re.sub(r\"#\", \"\", text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5a98ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    The Why Behind Microsoftâ€™s $19 Billion Nuance ...\n",
      "1    Make a change and an impart on yourself and ot...\n",
      "2    What are the biggest shitcoins? crypto btc bnb...\n",
      "3    crypto bitcoin cryptocurrency blockchain btc e...\n",
      "4    [1D] Bitcoin market is weakly trending up curr...\n",
      "5    ðŸ¤ Follow me on . Let's hunt for Bitcoins toget...\n",
      "6    Time to get in CRO folks, massive bull run is ...\n",
      "7    $ewt $btc $eth $dot $ada $link $snx $Inj $band...\n",
      "8    BTC tops, maxis take profits, hedge alts, alts...\n",
      "9    Live info FOREX Bitcoin BTC Gold backs off fur...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess_for_vader)\n",
    "\n",
    "print(df['text'].iloc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b8aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique languages detected in the dataset:\n",
      "['en' 'de' 'it' 'af' 'pl' 'hr' 'fi' 'unknown' 'nl' 'ca' 'pt' 'da' 'cy'\n",
      " 'so' 'es' 'fr' 'tl' 'ro' 'no' 'sv' 'id' 'tr' 'vi' 'et' 'sl' 'sw' 'ar'\n",
      " 'fa' 'ja' 'hu' 'th' 'sk' 'sq' 'lv' 'lt' 'cs' 'ru']\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Ensure reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "\n",
    "# Apply language detection\n",
    "df['lang'] = df['text'].astype(str).apply(detect_language)\n",
    "\n",
    "# Show all unique languages detected\n",
    "unique_languages = df['lang'].unique()\n",
    "\n",
    "print(\"Unique languages detected in the dataset:\")\n",
    "print(unique_languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6f570e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language frequencies in the dataset:\n",
      "lang\n",
      "en         706685\n",
      "de           1777\n",
      "ro           1565\n",
      "fr           1396\n",
      "pt           1259\n",
      "cy           1061\n",
      "nl            973\n",
      "it            787\n",
      "ca            751\n",
      "tl            642\n",
      "so            572\n",
      "af            387\n",
      "id            251\n",
      "da            247\n",
      "no            189\n",
      "vi            186\n",
      "unknown       183\n",
      "fi            181\n",
      "es            167\n",
      "pl            161\n",
      "tr            138\n",
      "sv            135\n",
      "sl            115\n",
      "et            104\n",
      "hr            102\n",
      "hu             43\n",
      "sw             40\n",
      "ar             36\n",
      "sq             35\n",
      "cs             32\n",
      "sk             22\n",
      "ja             19\n",
      "th             11\n",
      "lv              8\n",
      "lt              4\n",
      "fa              3\n",
      "ru              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def count_language_frequencies(df, lang_column='lang'):\n",
    "    return df[lang_column].value_counts()\n",
    "\n",
    "# Assuming df['lang'] has language codes\n",
    "lang_counts = count_language_frequencies(df)\n",
    "\n",
    "print(\"Language frequencies in the dataset:\")\n",
    "print(lang_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbed990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English tweets: 706685\n"
     ]
    }
   ],
   "source": [
    "def keep_only_english_tweets(df, lang_column='lang'):\n",
    "    return df[df[lang_column] == 'en'].copy()\n",
    "\n",
    "# Filtered DataFrame with only English tweets\n",
    "english_df = keep_only_english_tweets(df)\n",
    "\n",
    "# check how many remain\n",
    "print(f\"Number of English tweets: {len(english_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c4ce88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df.to_csv('filtered_tweets_feb_to_july.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b302f",
   "metadata": {},
   "source": [
    "## Assigning Labels to tweets Using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28e40c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aj281\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sia=SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_label(text):\n",
    "    # Get the sentiment scores\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    \n",
    "    # Determine the sentiment label based on the compound score\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0f2fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment counts:\n",
      "sentiment\n",
      "positive    368314\n",
      "neutral     246296\n",
      "negative    105658\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['sentiment'] = df['text'].apply(get_sentiment_label)\n",
    "# Count the number of tweets in each sentiment category \n",
    "sentiment_counts = df['sentiment'].value_counts()  \n",
    "print(\"Sentiment counts:\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Save the DataFrame with sentiment labels to a CSV file\n",
    "df.to_csv('tweets_with_sentiment_feb_to_july.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
